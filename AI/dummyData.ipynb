{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a391263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 479.6 MB 26 kB/s  eta 0:00:013   |▉                               | 12.6 MB 1.4 MB/s eta 0:05:41     |███████                         | 104.1 MB 1.9 MB/s eta 0:03:17     |████████▍                       | 126.0 MB 5.4 MB/s eta 0:01:06               | 138.7 MB 3.8 MB/s eta 0:01:31     |█████████▉                      | 148.2 MB 40.1 MB/s eta 0:00:09     |███████████▉                    | 177.8 MB 1.5 MB/s eta 0:03:21     |██████████████▏                 | 211.9 MB 1.5 MB/s eta 0:02:58     |███████████████                 | 225.1 MB 1.9 MB/s eta 0:02:12     |███████████████                 | 225.5 MB 1.9 MB/s eta 0:02:11     |███████████████▏                | 226.8 MB 1.9 MB/s eta 0:02:11    |████████████████                | 240.0 MB 4.0 MB/s eta 0:01:01��██████               | 254.0 MB 3.0 MB/s eta 0:01:15  | 254.5 MB 3.0 MB/s eta 0:01:15     |█████████████████               | 255.9 MB 444 kB/s eta 0:08:23     |█████████████████▊              | 266.4 MB 4.1 MB/s eta 0:00:52     |████████████████████            | 299.0 MB 4.1 MB/s eta 0:00:44 299.2 MB 4.1 MB/s eta 0:00:44.1 MB/s eta 0:00:44     |████████████████████            | 300.0 MB 1.4 MB/s eta 0:02:08     |████████████████████▏           | 301.5 MB 1.4 MB/s eta 0:02:07     |████████████████████▏           | 301.6 MB 1.4 MB/s eta 0:02:07     |████████████████████▏           | 301.6 MB 1.4 MB/s eta 0:02:07███████▏           | 301.8 MB 1.4 MB/s eta 0:02:073 MB 5.4 MB/s eta 0:00:33��████████████████▏           | 302.5 MB 5.4 MB/s eta 0:00:33     |████████████████████▎           | 303.3 MB 5.4 MB/s eta 0:00:33     |████████████████████▉           | 312.7 MB 1.7 MB/s eta 0:01:36     |█████████████████████▎          | 318.6 MB 4.9 MB/s eta 0:00:33     |█████████████████████▉          | 327.9 MB 2.5 MB/s eta 0:01:00 | 391.6 MB 1.6 MB/s eta 0:00:57     |██████████████████████████▋     | 398.2 MB 1.2 MB/s eta 0:01:10     |████████████████████████████    | 418.8 MB 1.7 MB/s eta 0:00:36     |████████████████████████████▎   | 424.6 MB 1.7 MB/s eta 0:00:33.9 MB 3.6 MB/s eta 0:00:15|████████████████████████████▌   | 427.1 MB 3.6 MB/s eta 0:00:15�█████████████████████████▌   | 427.7 MB 3.6 MB/s eta 0:00:15��███████████████████▋   | 429.4 MB 7.1 MB/s eta 0:00:08��███████████████████▊   | 430.3 MB 7.1 MB/s eta 0:00:07     |█████████████████████████████   | 434.3 MB 7.1 MB/s eta 0:00:07     |██████████████████████████████▊ | 459.8 MB 3.5 MB/s eta 0:00:06     |███████████████████████████████▌| 472.8 MB 1.4 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 428 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 317 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from tensorflow) (25.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from tensorflow) (44.0.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 270 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 703 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-2.0.1-cp38-cp38-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 635 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 833 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 2.0 MB/s eta 0:00:01     |████████████████████████████    | 204 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 609 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.20.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.7.0,>=0.6.1\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 778 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: opt-einsum, grpcio, libclang, numpy, wheel, astunparse, MarkupSafe, werkzeug, markdown, absl-py, protobuf, tensorboard-data-server, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, tensorboard, h5py, typing-extensions, tensorflow-estimator, tensorflow-io-gcs-filesystem, keras, google-pasta, termcolor, wrapt, flatbuffers, gast, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.13.2\n",
      "    Uninstalling typing-extensions-4.13.2:\n",
      "      Successfully uninstalled typing-extensions-4.13.2\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.3.1 astunparse-1.6.3 cachetools-5.5.2 flatbuffers-25.12.19 gast-0.4.0 google-auth-2.45.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.11.0 keras-2.13.1 libclang-18.1.1 markdown-3.7 numpy-1.24.3 oauthlib-3.3.1 opt-einsum-3.4.0 protobuf-4.25.8 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typing-extensions-4.5.0 werkzeug-3.0.6 wheel-0.45.1 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n",
      "Reconstruction error threshold for anomaly detection: 0.000528\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Estimated model detection 'accuracy': 95.37%\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4kzuqexy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4kzuqexy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model saved as model.h, ready for ESP32!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariam/NTI/analysis/myenv/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2025-12-29 13:29:14.668445: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-29 13:29:14.668485: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-29 13:29:14.668740: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp4kzuqexy\n",
      "2025-12-29 13:29:14.669767: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-29 13:29:14.669783: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp4kzuqexy\n",
      "2025-12-29 13:29:14.674147: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-29 13:29:14.727005: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp4kzuqexy\n",
      "2025-12-29 13:29:14.746585: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 77846 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "window_size = 50\n",
    "num_features = 3\n",
    "num_samples = 1000\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ SYNTHETIC SENSOR DATA\n",
    "# -----------------------------\n",
    "ax = np.random.normal(0, 0.02, num_samples)\n",
    "ay = np.random.normal(0, 0.02, num_samples)\n",
    "az = np.random.normal(9.81, 0.02, num_samples)\n",
    "current = np.random.normal(0.45, 0.01, num_samples)\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ SLIDING WINDOW FEATURES\n",
    "# -----------------------------\n",
    "features = []\n",
    "for i in range(len(ax) - window_size + 1):\n",
    "    win_ax = ax[i:i+window_size]\n",
    "    win_ay = ay[i:i+window_size]\n",
    "    win_az = az[i:i+window_size]\n",
    "    win_current = current[i:i+window_size]\n",
    "    \n",
    "    rms_v = np.sqrt(np.mean(win_ax**2 + win_ay**2 + win_az**2))\n",
    "    peak_v = np.max(np.sqrt(win_ax**2 + win_ay**2 + win_az**2))\n",
    "    mean_i = np.mean(win_current)\n",
    "    \n",
    "    features.append([rms_v, peak_v, mean_i])\n",
    "\n",
    "features = np.array(features, dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ NORMALIZE FEATURES\n",
    "# -----------------------------\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ AUTOENCODER\n",
    "# -----------------------------\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(num_features,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_features)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ TRAIN AUTOENCODER\n",
    "# -----------------------------\n",
    "history = model.fit(features_scaled, features_scaled, epochs=20, batch_size=16, verbose=0)\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ COMPUTE TRAINING RECONSTRUCTION ERROR\n",
    "# -----------------------------\n",
    "recon = model.predict(features_scaled)\n",
    "mse = np.mean((features_scaled - recon)**2, axis=1)\n",
    "\n",
    "threshold = np.mean(mse) + 3 * np.std(mse)\n",
    "print(f\"Reconstruction error threshold for anomaly detection: {threshold:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7️⃣ OPTIONAL: MODEL 'ACCURACY' ESTIMATE\n",
    "# -----------------------------\n",
    "# Simulate 5% anomalies\n",
    "num_anomalies = int(0.05 * len(features_scaled))\n",
    "anomalies = features_scaled[:num_anomalies] + np.random.normal(0, 0.2, (num_anomalies, num_features))\n",
    "\n",
    "# Compute MSE for anomalies\n",
    "recon_anomalies = model.predict(anomalies)\n",
    "mse_anomalies = np.mean((anomalies - recon_anomalies)**2, axis=1)\n",
    "\n",
    "# Detection: True Positive = anomaly detected, True Negative = normal detected\n",
    "true_positive = np.sum(mse_anomalies > threshold)\n",
    "true_negative = np.sum(mse[num_anomalies:] <= threshold)\n",
    "accuracy = (true_positive + true_negative) / len(features_scaled)\n",
    "print(f\"Estimated model detection 'accuracy': {accuracy*100:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8️⃣ QUANTIZE & SAVE MODEL AS model.h\n",
    "# -----------------------------\n",
    "def representative_dataset():\n",
    "    for i in range(0, len(features_scaled), window_size):\n",
    "        yield [features_scaled[i:i+window_size].astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "c_file = \"model.h\"\n",
    "hex_array = ','.join([str(b) for b in tflite_quant_model])\n",
    "with open(c_file, \"w\") as f:\n",
    "    f.write(\"const unsigned char model_tflite[] = {\")\n",
    "    f.write(hex_array)\n",
    "    f.write(\"};\\n\")\n",
    "    f.write(f\"const unsigned int model_tflite_len = {len(tflite_quant_model)};\\n\")\n",
    "\n",
    "print(\"Quantized TFLite model saved as model.h, ready for ESP32!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
